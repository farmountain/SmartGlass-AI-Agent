# Production Architecture Components

This document provides comprehensive documentation for the production-ready SmartGlass-AI-Agent architecture components implemented in Week 7-8.

## Overview

The production architecture consists of three core components:

1. **CLIPWorldModel**: CLIP-based scene understanding and intent inference
2. **SQLiteContextStore**: Persistent memory with full-text search
3. **RuleBasedPlanner**: Domain-specific task planning with safety constraints

These components work together to provide intelligent, context-aware assistance through the SmartGlass system.

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SmartGlassAgent                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
       â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input Audio â”‚  â”‚ Input Image  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚   CLIPWorldModel          â”‚  â† Scene Understanding + Intent
â”‚   - Extract Objects       â”‚
â”‚   - Classify Scene Type   â”‚
â”‚   - Infer User Intent     â”‚
â”‚   - Track State History   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ WorldState + UserIntent
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RuleBasedPlanner        â”‚  â† Task Decomposition
â”‚   - Generate Plan         â”‚
â”‚   - Apply Constraints     â”‚
â”‚   - Safety Filtering      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ Plan (steps)
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Skill Execution         â”‚  â† Execute Actions
â”‚   - Navigation            â”‚
â”‚   - Translation           â”‚
â”‚   - Identification        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ ExperienceFrame
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SQLiteContextStore      â”‚  â† Memory Persistence
â”‚   - Store Experiences     â”‚
â”‚   - Full-Text Search      â”‚
â”‚   - Session Management    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1. CLIPWorldModel

### Purpose

Provides scene understanding and intent inference using CLIP vision transformer.

### Features

- **Object Detection**: Zero-shot classification for 20 object categories
- **Scene Classification**: Recognizes 8 environment types (indoor/outdoor, office, restaurant, etc.)
- **Intent Inference**: Pattern-based matching for 6 intent types
- **State Tracking**: Maintains history of past states with change detection

### Usage

```python
from src.clip_world_model import CLIPWorldModel
from PIL import Image

# Initialize
world_model = CLIPWorldModel(
    confidence_threshold=0.15,  # Minimum confidence for object detection
    max_history=10,             # Number of past states to track
    device="cpu"                # or "cuda" for GPU
)

# Process image and query
image = Image.open("scene.jpg")
intent = world_model.infer_intent_from_query("What is this object?")

# Update world state
state = world_model.update(
    timestamp_ms=1234567890,
    objects=[],  # Optional pre-detected objects
    intent=intent,
    metadata={"session_id": "abc123"}
)

# Access current state
print(f"Intent: {state.intent.intent_type}")
print(f"Objects: {len(state.objects)}")
print(f"Scene: {state.metadata.get('scene_type')}")
```

### Configuration

| Parameter | Default | Description |
|-----------|---------|-------------|
| `confidence_threshold` | 0.15 | Minimum confidence for object detection (0-1) |
| `max_history` | 10 | Number of past WorldStates to retain |
| `device` | "cpu" | PyTorch device: "cpu", "cuda", "mps" |

### Supported Intents

| Intent Type | Trigger Words | Example |
|------------|---------------|---------|
| `navigate` | navigate, go to, take me, directions | "Navigate to coffee shop" |
| `translate` | translate, what does, mean in | "Translate this sign" |
| `identify` | what is, identify, recognize | "What is this object?" |
| `read` | read, show me text, ocr | "Read the menu" |
| `reminder` | remind, reminder, don't forget | "Remind me to buy milk" |
| `information` | tell me, information, about | "Tell me about this place" |

### Performance

- **Intent Inference**: 0.01ms mean, 0.02ms P95
- **Object Detection**: Requires CLIP model forward pass (not benchmarked in isolation)
- **State Update**: <0.1ms overhead

### File

ğŸ“„ [src/clip_world_model.py](../src/clip_world_model.py) (480 lines)

---

## 2. SQLiteContextStore

### Purpose

Provides persistent memory storage with full-text search capabilities using SQLite.

### Features

- **Full-Text Search**: FTS5 virtual tables for efficient keyword search
- **Session Management**: Group experiences by session with state tracking
- **Automatic Cleanup**: Configurable retention policy with automatic pruning
- **Statistics**: Query database metrics and usage statistics

### Usage

```python
from src.sqlite_context_store import SQLiteContextStore
from src.context_store import ExperienceFrame, ContextQuery
from datetime import datetime

# Initialize
store = SQLiteContextStore(
    db_path="./smartglass_memory.db",
    retention_days=30  # Auto-delete experiences older than 30 days
)

# Store experience
frame = ExperienceFrame(
    timestamp=datetime.now().isoformat(),
    query="Navigate to coffee shop",
    visual_context="",  # Base64-encoded image or description
    response="Found 3 nearby coffee shops",
    actions=[{"type": "navigate", "target": "Starbucks"}],
    metadata={"session_id": "session_001", "intent": "navigate"}
)
store.write(frame)

# Query experiences
query = ContextQuery(
    keywords=["coffee", "navigate"],
    limit=10,
    session_id="session_001",  # Optional: filter by session
    time_range_hours=24         # Optional: only recent experiences
)
result = store.query(query)

print(f"Found {result.total_count} matching experiences")
for frame in result.frames:
    print(f"- {frame.timestamp}: {frame.query}")

# Get statistics
stats = store.get_statistics()
print(f"Total frames: {stats['total_frames']}")
print(f"Unique sessions: {stats['unique_sessions']}")
print(f"DB size: {stats['db_size_bytes'] / 1024:.1f}KB")

# Close connection
store.close()
```

### Configuration

| Parameter | Default | Description |
|-----------|---------|-------------|
| `db_path` | ":memory:" | Path to SQLite database file or ":memory:" for in-memory |
| `retention_days` | 30 | Auto-delete experiences older than this (0 = no cleanup) |

### Schema

**experiences** table:
```sql
CREATE TABLE experiences (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp TEXT NOT NULL,
    query TEXT NOT NULL,
    visual_context TEXT,
    response TEXT,
    actions TEXT,
    metadata TEXT,
    session_id TEXT,
    created_at REAL NOT NULL
)
```

**experiences_fts** FTS5 virtual table for full-text search on `query` and `response`.

### Performance

- **Write**: 8.85ms mean, 15.09ms P95
- **Read (query)**: 0.29ms mean, 0.36ms P95
- **Database size**: ~1KB per experience frame

### File

ğŸ“„ [src/sqlite_context_store.py](../src/sqlite_context_store.py) (419 lines)

---

## 3. RuleBasedPlanner

### Purpose

Generates multi-step execution plans for user intents using domain-specific rules.

### Features

- **Domain-Specific Rules**: Tailored planning for 6 intent types
- **Constraint-Based Planning**: Respects max steps, timeout, minimum confidence
- **Safety Filtering**: Blocks dangerous actions (system commands, file access, network writes)
- **Confidence Scoring**: Assigns confidence to each step based on context

### Usage

```python
from src.rule_based_planner import RuleBasedPlanner
from src.world_model import WorldState, UserIntent
import time

# Initialize
planner = RuleBasedPlanner(
    default_max_steps=10,
    default_timeout_ms=5000,
    min_confidence=0.7,
    safety_mode=True  # Enable safety filtering
)

# Create world state
state = WorldState(
    timestamp_ms=int(time.time() * 1000),
    objects=[],
    intent=UserIntent(
        query="Translate this sign",
        intent_type="translate",
        confidence=0.9,
        slots={}
    ),
    metadata={}
)

# Generate plan
plan = planner.plan("Translate this sign", state)

print(f"Plan ID: {plan.plan_id}")
print(f"Intent: {plan.intent_type}")
print(f"Steps: {len(plan.steps)}")

for i, step in enumerate(plan.steps, 1):
    print(f"{i}. {step.action_type}")
    print(f"   Skill: {step.skill_id}")
    print(f"   Confidence: {step.confidence}")
```

### Configuration

| Parameter | Default | Description |
|-----------|---------|-------------|
| `default_max_steps` | 10 | Maximum steps per plan |
| `default_timeout_ms` | 5000 | Planning timeout in milliseconds |
| `min_confidence` | 0.7 | Minimum confidence threshold for steps |
| `safety_mode` | True | Enable safety filtering |

### Supported Intent Types

#### Navigate
1. Detect location
2. Plan route / Navigate
3. Display result

#### Translate
1. Capture image
2. OCR (extract text)
3. Detect language
4. Translate text
5. Display result

#### Identify
1. Capture image
2. Perceive (vision)
3. Recognize object
4. Retrieve information

#### Read
1. Capture image
2. OCR (extract text)
3. Display result

#### Reminder
1. Parse reminder details
2. Store reminder
3. Confirm creation

#### Information
1. Retrieve information
2. Summarize content
3. Display result

### Safety Filters

The following action types are blocked in safety mode:
- `system_command`
- `file_access`
- `network_write`

### Performance

- **Plan Generation**: 0.00ms mean, 0.01ms P95
- **Validation**: <0.01ms overhead

### File

ğŸ“„ [src/rule_based_planner.py](../src/rule_based_planner.py) (506 lines)

---

## Integration Example

### Full E2E Workflow

```python
from src.clip_world_model import CLIPWorldModel
from src.sqlite_context_store import SQLiteContextStore
from src.rule_based_planner import RuleBasedPlanner
from src.context_store import ExperienceFrame
from datetime import datetime
import time

# Initialize components
world_model = CLIPWorldModel(confidence_threshold=0.15)
context_store = SQLiteContextStore(db_path="./memory.db")
planner = RuleBasedPlanner()

# User query
query = "Navigate to the nearest coffee shop"

# 1. Infer intent
intent = world_model.infer_intent_from_query(query)
print(f"Intent: {intent.intent_type} (confidence: {intent.confidence})")

# 2. Update world state
state = world_model.update(
    timestamp_ms=int(time.time() * 1000),
    objects=[],
    intent=intent,
    metadata={"session_id": "user_session_001"}
)

# 3. Generate plan
plan = planner.plan(query, state)
print(f"Generated {len(plan.steps)} steps")

# 4. Execute plan (simulated)
response = f"Navigating to coffee shop..."
actions = [{"type": step.action_type, "skill": step.skill_id} for step in plan.steps]

# 5. Store experience
frame = ExperienceFrame(
    timestamp=datetime.now().isoformat(),
    query=query,
    visual_context="",
    response=response,
    actions=actions,
    metadata={
        "session_id": "user_session_001",
        "intent_type": intent.intent_type,
        "plan_id": plan.plan_id
    }
)
context_store.write(frame)

print(f"Experience stored with {len(actions)} actions")

# 6. Query similar past experiences
from src.context_store import ContextQuery

similar = context_store.query(ContextQuery(
    keywords=["coffee", "navigate"],
    limit=5
))

print(f"Found {similar.total_count} similar past experiences")
```

---

## Performance Summary

Benchmarked on 100 trials (50 for E2E):

| Component | Mean | P50 | P95 | P99 |
|-----------|------|-----|-----|-----|
| **CLIPWorldModel** (Intent) | 0.01ms | 0.01ms | 0.02ms | 0.04ms |
| **SQLiteContextStore** (Write) | 8.85ms | - | 15.09ms | - |
| **SQLiteContextStore** (Read) | 0.29ms | - | 0.36ms | - |
| **RuleBasedPlanner** | 0.00ms | - | 0.01ms | - |
| **E2E Workflow** | 9.20ms | 9.11ms | 15.60ms | 16.78ms |

**âœ… Target: <1s E2E latency - PASS (984ms under target)**

Component breakdown:
- Memory Operations: 96.2%
- Intent Inference: 0.1%
- Plan Generation: 0.0%

---

## Testing

### Validation Script

Run comprehensive validation tests:

```bash
python validate_production_components.py
```

Output:
```
âœ… PASS - SQLiteContextStore
âœ… PASS - CLIPWorldModel  
âœ… PASS - RuleBasedPlanner
âœ… PASS - Integrated Workflow

Overall: 4/4 tests passed (100%)
```

### Performance Benchmark

Run performance benchmarks:

```bash
python bench/production_bench.py
```

### Integration Tests

Run pytest integration tests:

```bash
pytest tests/test_production_components.py -v
```

---

## Configuration Best Practices

### Production Deployment

```python
# Recommended production configuration
world_model = CLIPWorldModel(
    confidence_threshold=0.20,  # Higher threshold for production
    max_history=5,              # Balance memory vs history
    device="cuda"               # Use GPU if available
)

context_store = SQLiteContextStore(
    db_path="/data/smartglass_memory.db",  # Persistent storage
    retention_days=90                       # 3-month retention
)

planner = RuleBasedPlanner(
    default_max_steps=8,        # Shorter plans for faster execution
    default_timeout_ms=3000,    # 3s timeout
    min_confidence=0.8,         # High confidence for production
    safety_mode=True            # Always enable safety
)
```

### Development/Testing

```python
# Development configuration for faster iteration
world_model = CLIPWorldModel(
    confidence_threshold=0.10,  # Lower threshold for more detections
    max_history=20,             # More history for debugging
    device="cpu"                # Consistent behavior across machines
)

context_store = SQLiteContextStore(
    db_path=":memory:",        # In-memory for fast tests
    retention_days=0            # No cleanup during dev
)

planner = RuleBasedPlanner(
    default_max_steps=15,       # Allow complex plans
    min_confidence=0.5,         # Lower bar for experimentation
    safety_mode=False           # Disable safety for testing
)
```

---

## Troubleshooting

### Import Errors

If you encounter `ModuleNotFoundError` or relative import issues:

```python
# Option 1: Add project root to path
import sys
from pathlib import Path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# Option 2: Use absolute imports
from src.clip_world_model import CLIPWorldModel
from src.sqlite_context_store import SQLiteContextStore
from src.rule_based_planner import RuleBasedPlanner
```

### SQLite Database Locked

If SQLite shows "database is locked" errors:

```python
# Use WAL mode for better concurrency
import sqlite3
conn = sqlite3.connect("memory.db")
conn.execute("PRAGMA journal_mode=WAL")
conn.close()
```

### Memory Growth

If memory usage grows over time:

```python
# Enable automatic cleanup
store = SQLiteContextStore(
    db_path="memory.db",
    retention_days=30  # Auto-delete old experiences
)

# Or manually trigger cleanup
store._cleanup_old_experiences()
```

---

## Future Enhancements

### Week 8-9 Roadmap

1. **Azure Telemetry**: ApplicationInsightsCollector for cloud monitoring
2. **Hardware Validation**: Test on Meta Ray-Ban device
3. **LLM Integration**: Replace rule-based planner with LLM for more flexible planning
4. **Vector Search**: Add FAISS/Pinecone for semantic memory retrieval
5. **Streaming**: Support real-time state updates

---

## References

- **ABC Interfaces**: [src/world_model.py](../src/world_model.py), [src/context_store.py](../src/context_store.py), [src/planner.py](../src/planner.py)
- **Implementation Files**: [src/clip_world_model.py](../src/clip_world_model.py), [src/sqlite_context_store.py](../src/sqlite_context_store.py), [src/rule_based_planner.py](../src/rule_based_planner.py)
- **Tests**: [validate_production_components.py](../validate_production_components.py), [tests/test_production_components.py](../tests/test_production_components.py)
- **Benchmarks**: [bench/production_bench.py](../bench/production_bench.py)

---

## License

See [LICENSE](../LICENSE) for terms.
