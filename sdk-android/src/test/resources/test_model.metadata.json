{
  "tokenizer": {
    "vocab": ["<pad>", "<unk>", "hello", "world", "test", "token", "simple", "example"],
    "lowercase": true,
    "pad_token_id": 0,
    "unk_token_id": 1,
    "max_length": 64
  },
  "inputs": {
    "input_ids": {
      "shape": [1, -1]
    }
  },
  "outputs": {
    "logits": {
      "shape": [1, -1, 8]
    }
  }
}
