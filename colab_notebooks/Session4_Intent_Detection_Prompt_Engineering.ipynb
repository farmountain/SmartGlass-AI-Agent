{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farmountain/SmartGlass-AI-Agent/blob/main/colab_notebooks/Session4_Intent_Detection_Prompt_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be202513",
      "metadata": {
        "id": "be202513"
      },
      "source": [
        "# üéØ Session 04: Intent Detection + Prompt Engineering\n",
        "This session focuses on:\n",
        "- Detecting user intent from transcribed speech\n",
        "- Crafting better prompts for LLMs\n",
        "- Generating dynamic LLM prompts from detected intent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a992b40",
      "metadata": {
        "id": "8a992b40"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ Install dependencies\n",
        "!pip install -q openai-whisper transformers torch torchaudio pydub gTTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ee68dcc",
      "metadata": {
        "id": "8ee68dcc"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ Step 1: Transcribe audio (simulate smartglass voice input)\n",
        "import whisper\n",
        "from pydub import AudioSegment\n",
        "from gtts import gTTS\n",
        "import os\n",
        "\n",
        "# Generate a sample intent statement\n",
        "tts = gTTS('Find me the nearest Italian restaurant', lang='en')\n",
        "tts.save('intent_request.mp3')\n",
        "\n",
        "# Convert to WAV\n",
        "audio = AudioSegment.from_file('intent_request.mp3')\n",
        "audio.export('intent_request.wav', format='wav')\n",
        "\n",
        "# Transcribe\n",
        "model = whisper.load_model('base')\n",
        "result = model.transcribe('intent_request.wav')\n",
        "print('üó£Ô∏è Transcribed Text:', result['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce8048d0",
      "metadata": {
        "id": "ce8048d0"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ Step 2: Intent classification using keyword heuristics\n",
        "text = result['text'].lower()\n",
        "intent = 'unknown'\n",
        "if 'restaurant' in text or 'food' in text:\n",
        "    intent = 'find_restaurant'\n",
        "elif 'navigate' in text or 'direction' in text:\n",
        "    intent = 'get_directions'\n",
        "elif 'weather' in text:\n",
        "    intent = 'check_weather'\n",
        "print('üéØ Detected Intent:', intent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "094cd54f",
      "metadata": {
        "id": "094cd54f"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ Step 3: Dynamic prompt generation\n",
        "from transformers import pipeline\n",
        "llm = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "prompt_map = {\n",
        "    'find_restaurant': 'Suggest a popular nearby Italian restaurant with a short description.',\n",
        "    'get_directions': 'Give me step-by-step directions to the nearest train station.',\n",
        "    'check_weather': 'What is the weather like right now in Singapore?'\n",
        "}\n",
        "\n",
        "if intent in prompt_map:\n",
        "    prompt = prompt_map[intent]\n",
        "    response = llm(prompt, max_length=50, do_sample=True)[0]['generated_text']\n",
        "    print('ü§ñ LLM Response:', response)\n",
        "else:\n",
        "    print('ü§ñ No matching prompt for this intent.')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}